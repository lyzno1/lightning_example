{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOygiAiuAHu81TUH5jYtX9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyzno1/lightning_example/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-Rs41Bm7D6C-",
        "outputId": "8132a133-ab1d-48ea-f9a5-c7d314db3792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ÏïàÎÖïÌïòÏÑ∏Ïöî üëè (hello in korean!)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"ÏïàÎÖïÌïòÏÑ∏Ïöî üëè (hello in korean!)\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ord(x) for x in \"ÏïàÎÖïÌïòÏÑ∏Ïöî üëè (hello in korean!)\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8omGmIp1EPwG",
        "outputId": "067c1c12-7264-4088-bda3-7746aa0ec46f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50504,\n",
              " 45397,\n",
              " 54616,\n",
              " 49464,\n",
              " 50836,\n",
              " 32,\n",
              " 128079,\n",
              " 32,\n",
              " 40,\n",
              " 104,\n",
              " 101,\n",
              " 108,\n",
              " 108,\n",
              " 111,\n",
              " 32,\n",
              " 105,\n",
              " 110,\n",
              " 32,\n",
              " 107,\n",
              " 111,\n",
              " 114,\n",
              " 101,\n",
              " 97,\n",
              " 110,\n",
              " 33,\n",
              " 41]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(\"ÏïàÎÖïÌïòÏÑ∏Ïöî üëè (hello in korean!)\".encode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNGBiph1Eg9W",
        "outputId": "93917eba-ee08-4c54-a661-389ffff357ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[236,\n",
              " 149,\n",
              " 136,\n",
              " 235,\n",
              " 133,\n",
              " 149,\n",
              " 237,\n",
              " 149,\n",
              " 152,\n",
              " 236,\n",
              " 132,\n",
              " 184,\n",
              " 236,\n",
              " 154,\n",
              " 148,\n",
              " 32,\n",
              " 240,\n",
              " 159,\n",
              " 145,\n",
              " 143,\n",
              " 32,\n",
              " 40,\n",
              " 104,\n",
              " 101,\n",
              " 108,\n",
              " 108,\n",
              " 111,\n",
              " 32,\n",
              " 105,\n",
              " 110,\n",
              " 32,\n",
              " 107,\n",
              " 111,\n",
              " 114,\n",
              " 101,\n",
              " 97,\n",
              " 110,\n",
              " 33,\n",
              " 41]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text from https://www.reedbeta.com/blog/programmers-intro-to-unicode/\n",
        "text = \"ÔºµÔΩéÔΩâÔΩÉÔΩèÔΩÑÔΩÖ! üÖ§üÖùüÖòüÖíüÖûüÖìüÖî‚ÄΩ üá∫‚Äåüá≥‚ÄåüáÆ‚Äåüá®‚Äåüá¥‚Äåüá©‚Äåüá™! üòÑ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to ‚Äúsupport Unicode‚Äù in our software (whatever that means‚Äîlike using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I don‚Äôt blame programmers for still finding the whole thing mysterious, even 30 years after Unicode‚Äôs inception.\"\n",
        "tokens = text.encode(\"utf-8\") # raw bytes\n",
        "tokens = list(map(int, tokens)) # convert to a list of integers in range 0..255 for convenience\n",
        "print('---')\n",
        "print(text)\n",
        "print(\"length\", len(text))\n",
        "print('---')\n",
        "print(tokens)\n",
        "print(\"length\", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbx7C_6IFZHz",
        "outputId": "3aff752b-0233-4da8-947d-18901b7d3c7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "ÔºµÔΩéÔΩâÔΩÉÔΩèÔΩÑÔΩÖ! üÖ§üÖùüÖòüÖíüÖûüÖìüÖî‚ÄΩ üá∫‚Äåüá≥‚ÄåüáÆ‚Äåüá®‚Äåüá¥‚Äåüá©‚Äåüá™! üòÑ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to ‚Äúsupport Unicode‚Äù in our software (whatever that means‚Äîlike using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I don‚Äôt blame programmers for still finding the whole thing mysterious, even 30 years after Unicode‚Äôs inception.\n",
            "length 533\n",
            "---\n",
            "[239, 188, 181, 239, 189, 142, 239, 189, 137, 239, 189, 131, 239, 189, 143, 239, 189, 132, 239, 189, 133, 33, 32, 240, 159, 133, 164, 240, 159, 133, 157, 240, 159, 133, 152, 240, 159, 133, 146, 240, 159, 133, 158, 240, 159, 133, 147, 240, 159, 133, 148, 226, 128, 189, 32, 240, 159, 135, 186, 226, 128, 140, 240, 159, 135, 179, 226, 128, 140, 240, 159, 135, 174, 226, 128, 140, 240, 159, 135, 168, 226, 128, 140, 240, 159, 135, 180, 226, 128, 140, 240, 159, 135, 169, 226, 128, 140, 240, 159, 135, 170, 33, 32, 240, 159, 152, 132, 32, 84, 104, 101, 32, 118, 101, 114, 121, 32, 110, 97, 109, 101, 32, 115, 116, 114, 105, 107, 101, 115, 32, 102, 101, 97, 114, 32, 97, 110, 100, 32, 97, 119, 101, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 104, 101, 97, 114, 116, 115, 32, 111, 102, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 119, 111, 114, 108, 100, 119, 105, 100, 101, 46, 32, 87, 101, 32, 97, 108, 108, 32, 107, 110, 111, 119, 32, 119, 101, 32, 111, 117, 103, 104, 116, 32, 116, 111, 32, 226, 128, 156, 115, 117, 112, 112, 111, 114, 116, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 157, 32, 105, 110, 32, 111, 117, 114, 32, 115, 111, 102, 116, 119, 97, 114, 101, 32, 40, 119, 104, 97, 116, 101, 118, 101, 114, 32, 116, 104, 97, 116, 32, 109, 101, 97, 110, 115, 226, 128, 148, 108, 105, 107, 101, 32, 117, 115, 105, 110, 103, 32, 119, 99, 104, 97, 114, 95, 116, 32, 102, 111, 114, 32, 97, 108, 108, 32, 116, 104, 101, 32, 115, 116, 114, 105, 110, 103, 115, 44, 32, 114, 105, 103, 104, 116, 63, 41, 46, 32, 66, 117, 116, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 97, 110, 32, 98, 101, 32, 97, 98, 115, 116, 114, 117, 115, 101, 44, 32, 97, 110, 100, 32, 100, 105, 118, 105, 110, 103, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 116, 104, 111, 117, 115, 97, 110, 100, 45, 112, 97, 103, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 83, 116, 97, 110, 100, 97, 114, 100, 32, 112, 108, 117, 115, 32, 105, 116, 115, 32, 100, 111, 122, 101, 110, 115, 32, 111, 102, 32, 115, 117, 112, 112, 108, 101, 109, 101, 110, 116, 97, 114, 121, 32, 97, 110, 110, 101, 120, 101, 115, 44, 32, 114, 101, 112, 111, 114, 116, 115, 44, 32, 97, 110, 100, 32, 110, 111, 116, 101, 115, 32, 99, 97, 110, 32, 98, 101, 32, 109, 111, 114, 101, 32, 116, 104, 97, 110, 32, 97, 32, 108, 105, 116, 116, 108, 101, 32, 105, 110, 116, 105, 109, 105, 100, 97, 116, 105, 110, 103, 46, 32, 73, 32, 100, 111, 110, 226, 128, 153, 116, 32, 98, 108, 97, 109, 101, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 102, 111, 114, 32, 115, 116, 105, 108, 108, 32, 102, 105, 110, 100, 105, 110, 103, 32, 116, 104, 101, 32, 119, 104, 111, 108, 101, 32, 116, 104, 105, 110, 103, 32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115, 44, 32, 101, 118, 101, 110, 32, 51, 48, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 153, 115, 32, 105, 110, 99, 101, 112, 116, 105, 111, 110, 46]\n",
            "length 616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chr(101), chr(32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB3vCuP0JBdy",
        "outputId": "fcd8578b-6b43-46c1-989b-a20467258b1e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('e', ' ')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "  counts = {}\n",
        "  for pair in zip(ids, ids[1:]): # Pythonic way to iterate consecutive elements\n",
        "    counts[pair] = counts.get(pair, 0) + 1\n",
        "  return counts\n",
        "\n",
        "stats = get_stats(tokens)\n",
        "# print(stats)\n",
        "# print(sorted(((v,k) for k,v in stats.items()), reverse=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb7eW91VH6TN",
        "outputId": "c5d224b2-b311-45a8-8947-a0127317fc1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(20, (101, 32)), (15, (240, 159)), (12, (226, 128)), (12, (105, 110)), (10, (115, 32)), (10, (97, 110)), (10, (32, 97)), (9, (32, 116)), (8, (116, 104)), (7, (159, 135)), (7, (159, 133)), (7, (97, 114)), (6, (239, 189)), (6, (140, 240)), (6, (128, 140)), (6, (116, 32)), (6, (114, 32)), (6, (111, 114)), (6, (110, 103)), (6, (110, 100)), (6, (109, 101)), (6, (104, 101)), (6, (101, 114)), (6, (32, 105)), (5, (117, 115)), (5, (115, 116)), (5, (110, 32)), (5, (100, 101)), (5, (44, 32)), (5, (32, 115)), (4, (116, 105)), (4, (116, 101)), (4, (115, 44)), (4, (114, 105)), (4, (111, 117)), (4, (111, 100)), (4, (110, 116)), (4, (110, 105)), (4, (105, 99)), (4, (104, 97)), (4, (103, 32)), (4, (101, 97)), (4, (100, 32)), (4, (99, 111)), (4, (97, 109)), (4, (85, 110)), (4, (32, 119)), (4, (32, 111)), (4, (32, 102)), (4, (32, 85)), (3, (118, 101)), (3, (116, 115)), (3, (116, 114)), (3, (116, 111)), (3, (114, 116)), (3, (114, 115)), (3, (114, 101)), (3, (111, 102)), (3, (111, 32)), (3, (108, 108)), (3, (108, 101)), (3, (108, 32)), (3, (101, 115)), (3, (101, 110)), (3, (97, 116)), (3, (46, 32)), (3, (32, 240)), (3, (32, 112)), (3, (32, 109)), (3, (32, 100)), (3, (32, 98)), (2, (128, 153)), (2, (121, 32)), (2, (119, 104)), (2, (119, 101)), (2, (117, 112)), (2, (116, 97)), (2, (115, 117)), (2, (114, 121)), (2, (114, 111)), (2, (114, 97)), (2, (112, 114)), (2, (112, 112)), (2, (112, 111)), (2, (112, 108)), (2, (111, 110)), (2, (111, 103)), (2, (110, 115)), (2, (110, 111)), (2, (109, 109)), (2, (108, 105)), (2, (107, 101)), (2, (105, 116)), (2, (105, 111)), (2, (105, 107)), (2, (105, 100)), (2, (104, 116)), (2, (104, 111)), (2, (103, 114)), (2, (103, 104)), (2, (102, 116)), (2, (102, 111)), (2, (102, 32)), (2, (101, 226)), (2, (101, 118)), (2, (101, 112)), (2, (100, 111)), (2, (100, 105)), (2, (100, 97)), (2, (99, 97)), (2, (98, 101)), (2, (97, 108)), (2, (33, 32)), (2, (32, 114)), (2, (32, 110)), (2, (32, 99)), (1, (239, 188)), (1, (189, 143)), (1, (189, 142)), (1, (189, 137)), (1, (189, 133)), (1, (189, 132)), (1, (189, 131)), (1, (189, 32)), (1, (188, 181)), (1, (186, 226)), (1, (181, 239)), (1, (180, 226)), (1, (179, 226)), (1, (174, 226)), (1, (170, 33)), (1, (169, 226)), (1, (168, 226)), (1, (164, 240)), (1, (159, 152)), (1, (158, 240)), (1, (157, 240)), (1, (157, 32)), (1, (156, 115)), (1, (153, 116)), (1, (153, 115)), (1, (152, 240)), (1, (152, 132)), (1, (148, 226)), (1, (148, 108)), (1, (147, 240)), (1, (146, 240)), (1, (143, 239)), (1, (142, 239)), (1, (137, 239)), (1, (135, 186)), (1, (135, 180)), (1, (135, 179)), (1, (135, 174)), (1, (135, 170)), (1, (135, 169)), (1, (135, 168)), (1, (133, 164)), (1, (133, 158)), (1, (133, 157)), (1, (133, 152)), (1, (133, 148)), (1, (133, 147)), (1, (133, 146)), (1, (133, 33)), (1, (132, 239)), (1, (132, 32)), (1, (131, 239)), (1, (128, 189)), (1, (128, 157)), (1, (128, 156)), (1, (128, 148)), (1, (122, 101)), (1, (121, 115)), (1, (121, 101)), (1, (120, 101)), (1, (119, 111)), (1, (119, 105)), (1, (119, 99)), (1, (119, 97)), (1, (119, 32)), (1, (118, 105)), (1, (117, 116)), (1, (117, 114)), (1, (117, 103)), (1, (116, 119)), (1, (116, 116)), (1, (116, 108)), (1, (116, 63)), (1, (115, 226)), (1, (115, 111)), (1, (115, 105)), (1, (115, 101)), (1, (115, 97)), (1, (114, 117)), (1, (114, 108)), (1, (114, 100)), (1, (114, 95)), (1, (112, 116)), (1, (112, 97)), (1, (111, 122)), (1, (111, 119)), (1, (111, 116)), (1, (111, 108)), (1, (110, 226)), (1, (110, 110)), (1, (110, 101)), (1, (110, 99)), (1, (110, 97)), (1, (110, 46)), (1, (109, 121)), (1, (109, 111)), (1, (109, 105)), (1, (108, 117)), (1, (108, 100)), (1, (108, 97)), (1, (107, 110)), (1, (105, 118)), (1, (105, 109)), (1, (105, 108)), (1, (105, 103)), (1, (104, 105)), (1, (103, 115)), (1, (103, 101)), (1, (103, 46)), (1, (102, 105)), (1, (102, 101)), (1, (101, 120)), (1, (101, 109)), (1, (101, 46)), (1, (101, 44)), (1, (100, 119)), (1, (100, 45)), (1, (99, 104)), (1, (99, 101)), (1, (98, 115)), (1, (98, 108)), (1, (97, 119)), (1, (97, 103)), (1, (97, 102)), (1, (97, 98)), (1, (97, 32)), (1, (95, 116)), (1, (87, 101)), (1, (84, 104)), (1, (83, 116)), (1, (73, 32)), (1, (66, 117)), (1, (63, 41)), (1, (51, 48)), (1, (48, 32)), (1, (45, 112)), (1, (41, 46)), (1, (40, 119)), (1, (32, 226)), (1, (32, 121)), (1, (32, 118)), (1, (32, 117)), (1, (32, 108)), (1, (32, 107)), (1, (32, 104)), (1, (32, 101)), (1, (32, 87)), (1, (32, 84)), (1, (32, 83)), (1, (32, 73)), (1, (32, 66)), (1, (32, 51)), (1, (32, 40))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_pair = max(stats, key=stats.get)\n",
        "top_pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWhsn6lCIetr",
        "outputId": "4e8465ae-3fe5-4456-9afe-05e75c524e4d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(ids, pair, idx):\n",
        "  # in the list of ints(ids), replace all consecutive occurences of pair with the new token idx\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    # if we are not at the very last position AND  the pair matches, replace it\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids\n",
        "\n",
        "print(merge([5, 6, 6, 7, 9, 1], (6, 7), 99))\n",
        "\n",
        "tokens2 = merge(tokens, top_pair, 256)\n",
        "print(tokens2)\n",
        "print(\"length:\", len(tokens2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95ggXDM4JVvS",
        "outputId": "49d37a39-5b3e-4ce9-a767-292171bfdb6d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 6, 99, 9, 1]\n",
            "[239, 188, 181, 239, 189, 142, 239, 189, 137, 239, 189, 131, 239, 189, 143, 239, 189, 132, 239, 189, 133, 33, 32, 240, 159, 133, 164, 240, 159, 133, 157, 240, 159, 133, 152, 240, 159, 133, 146, 240, 159, 133, 158, 240, 159, 133, 147, 240, 159, 133, 148, 226, 128, 189, 32, 240, 159, 135, 186, 226, 128, 140, 240, 159, 135, 179, 226, 128, 140, 240, 159, 135, 174, 226, 128, 140, 240, 159, 135, 168, 226, 128, 140, 240, 159, 135, 180, 226, 128, 140, 240, 159, 135, 169, 226, 128, 140, 240, 159, 135, 170, 33, 32, 240, 159, 152, 132, 32, 84, 104, 256, 118, 101, 114, 121, 32, 110, 97, 109, 256, 115, 116, 114, 105, 107, 101, 115, 32, 102, 101, 97, 114, 32, 97, 110, 100, 32, 97, 119, 256, 105, 110, 116, 111, 32, 116, 104, 256, 104, 101, 97, 114, 116, 115, 32, 111, 102, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 119, 111, 114, 108, 100, 119, 105, 100, 101, 46, 32, 87, 256, 97, 108, 108, 32, 107, 110, 111, 119, 32, 119, 256, 111, 117, 103, 104, 116, 32, 116, 111, 32, 226, 128, 156, 115, 117, 112, 112, 111, 114, 116, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 157, 32, 105, 110, 32, 111, 117, 114, 32, 115, 111, 102, 116, 119, 97, 114, 256, 40, 119, 104, 97, 116, 101, 118, 101, 114, 32, 116, 104, 97, 116, 32, 109, 101, 97, 110, 115, 226, 128, 148, 108, 105, 107, 256, 117, 115, 105, 110, 103, 32, 119, 99, 104, 97, 114, 95, 116, 32, 102, 111, 114, 32, 97, 108, 108, 32, 116, 104, 256, 115, 116, 114, 105, 110, 103, 115, 44, 32, 114, 105, 103, 104, 116, 63, 41, 46, 32, 66, 117, 116, 32, 85, 110, 105, 99, 111, 100, 256, 99, 97, 110, 32, 98, 256, 97, 98, 115, 116, 114, 117, 115, 101, 44, 32, 97, 110, 100, 32, 100, 105, 118, 105, 110, 103, 32, 105, 110, 116, 111, 32, 116, 104, 256, 116, 104, 111, 117, 115, 97, 110, 100, 45, 112, 97, 103, 256, 85, 110, 105, 99, 111, 100, 256, 83, 116, 97, 110, 100, 97, 114, 100, 32, 112, 108, 117, 115, 32, 105, 116, 115, 32, 100, 111, 122, 101, 110, 115, 32, 111, 102, 32, 115, 117, 112, 112, 108, 101, 109, 101, 110, 116, 97, 114, 121, 32, 97, 110, 110, 101, 120, 101, 115, 44, 32, 114, 101, 112, 111, 114, 116, 115, 44, 32, 97, 110, 100, 32, 110, 111, 116, 101, 115, 32, 99, 97, 110, 32, 98, 256, 109, 111, 114, 256, 116, 104, 97, 110, 32, 97, 32, 108, 105, 116, 116, 108, 256, 105, 110, 116, 105, 109, 105, 100, 97, 116, 105, 110, 103, 46, 32, 73, 32, 100, 111, 110, 226, 128, 153, 116, 32, 98, 108, 97, 109, 256, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 102, 111, 114, 32, 115, 116, 105, 108, 108, 32, 102, 105, 110, 100, 105, 110, 103, 32, 116, 104, 256, 119, 104, 111, 108, 256, 116, 104, 105, 110, 103, 32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115, 44, 32, 101, 118, 101, 110, 32, 51, 48, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 153, 115, 32, 105, 110, 99, 101, 112, 116, 105, 111, 110, 46]\n",
            "length: 596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making the training text longer to have more representative token statistics\n",
        "# text from https://www.reedbeta.com/blog/programmers-intro-to-unicode/\n",
        "text = \"ÔºµÔΩéÔΩâÔΩÉÔΩèÔΩÑÔΩÖ! üÖ§üÖùüÖòüÖíüÖûüÖìüÖî‚ÄΩ üá∫‚Äåüá≥‚ÄåüáÆ‚Äåüá®‚Äåüá¥‚Äåüá©‚Äåüá™! üòÑ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to ‚Äúsupport Unicode‚Äù in our software (whatever that means‚Äîlike using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I don‚Äôt blame programmers for still finding the whole thing mysterious, even 30 years after Unicode‚Äôs inception.\"\n",
        "tokens = text.encode(\"utf-8\") # raw bytes\n",
        "tokens = list(map(int, tokens)) # convert to a list of integers in range 0..255 for convenience"
      ],
      "metadata": {
        "id": "lKm-R730KBU0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 276 # the desired final vocabulary size\n",
        "num_merges = vocab_size - 256\n",
        "ids = list(tokens) # copy so we don't destroy the original list\n",
        "\n",
        "merges = {} # (int, int) -> int\n",
        "for i in range(num_merges):\n",
        "  stats = get_stats(ids)\n",
        "  pair = max(stats, key=stats.get)\n",
        "  idx = 256 + i\n",
        "  print(f\"merging {pair} into a new token {idx}\")\n",
        "  ids = merge(ids, pair, idx)\n",
        "  merges[pair] = idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIEjIyM-LDLk",
        "outputId": "a5417b39-cf00-461a-f3ef-ee82b5f2d033"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (101, 32) into a new token 256\n",
            "merging (240, 159) into a new token 257\n",
            "merging (226, 128) into a new token 258\n",
            "merging (105, 110) into a new token 259\n",
            "merging (115, 32) into a new token 260\n",
            "merging (97, 110) into a new token 261\n",
            "merging (116, 104) into a new token 262\n",
            "merging (257, 133) into a new token 263\n",
            "merging (257, 135) into a new token 264\n",
            "merging (97, 114) into a new token 265\n",
            "merging (239, 189) into a new token 266\n",
            "merging (258, 140) into a new token 267\n",
            "merging (267, 264) into a new token 268\n",
            "merging (101, 114) into a new token 269\n",
            "merging (111, 114) into a new token 270\n",
            "merging (116, 32) into a new token 271\n",
            "merging (259, 103) into a new token 272\n",
            "merging (115, 116) into a new token 273\n",
            "merging (261, 100) into a new token 274\n",
            "merging (32, 262) into a new token 275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tokens length:\", len(tokens))\n",
        "print(\"ids length:\", len(ids))\n",
        "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUxuvkBdMG31",
        "outputId": "437bbbd7-b6ca-4d9a-8dd1-c2c2c997d1bd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens length: 616\n",
            "ids length: 451\n",
            "compression ratio: 1.37X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1), idx in merges.items():\n",
        "  vocab[idx] = vocab[p0] + vocab[p1]\n",
        "\n",
        "def decode(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors='replace')\n",
        "  return text\n",
        "\n",
        "print(decode([128]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U75baOWYMfqd",
        "outputId": "0e032a0e-31e7-4aaa-b654-6d2432000613"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÔøΩ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_auCYsUPlBc",
        "outputId": "e09d3a19-5014-432d-dee5-5344696fb872"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(101, 32): 256,\n",
              " (240, 159): 257,\n",
              " (226, 128): 258,\n",
              " (105, 110): 259,\n",
              " (115, 32): 260,\n",
              " (97, 110): 261,\n",
              " (116, 104): 262,\n",
              " (257, 133): 263,\n",
              " (257, 135): 264,\n",
              " (97, 114): 265,\n",
              " (239, 189): 266,\n",
              " (258, 140): 267,\n",
              " (267, 264): 268,\n",
              " (101, 114): 269,\n",
              " (111, 114): 270,\n",
              " (116, 32): 271,\n",
              " (259, 103): 272,\n",
              " (115, 116): 273,\n",
              " (261, 100): 274,\n",
              " (32, 262): 275}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "  # giving a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "\n",
        "print(encode(\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRZ_scT9Owhi",
        "outputId": "b102e044-4e5a-4c53-caaa-a7b5c992a0d6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(encode(\"hello world\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bte_PiIaQ1fy",
        "outputId": "2d0fa1bf-fddd-43fc-eba1-ee6375b54daf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = decode(encode(text))\n",
        "print(text2 == text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzO5X1XKRF2f",
        "outputId": "dfaff75a-c455-4f59-c5cd-9a03fab52b97"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valtext = \"As soon as you start to study Unicode, it becomes clear that it represents a large jump in complexity over character sets like ASCII that you may be more familiar with. It‚Äôs not just that Unicode contains a much larger number of characters, although that‚Äôs part of it. \"\n",
        "valtext2 = decode(encode(valtext))\n",
        "print(valtext2 == valtext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCtnINaVRKzB",
        "outputId": "316762ae-1651-460f-99ce-7ee1c182b24e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "gpt2pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
        "\n",
        "print(re.findall(gpt2pat, \"Hello've world123 how's are you!!!?  \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FePp81TqRYAT",
        "outputId": "306f163a-627d-4358-c859-ceb1e94ec509"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', \"'ve\", ' world', '123', ' how', \"'s\", ' are', ' you', '!!!?', '  ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"\"\"\n",
        "for i in range(1, 101):\n",
        "  if i % 3 == 0 and i % 5 == 0:\n",
        "    print(\"FizzBuzz\")\n",
        "  elif i % 3 == 0:\n",
        "    print(\"Fizz\")\n",
        "  elif i % 5 == 0:\n",
        "    print(\"Buzz\")\n",
        "  else:\n",
        "    print(i)\n",
        "\"\"\"\n",
        "print(re.findall(gpt2pat, example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnpRxcR-SgWt",
        "outputId": "cb7cfeaf-543f-4203-f9cd-e1e984f07e7e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', 'for', ' i', ' in', ' range', '(', '1', ',', ' 101', '):', '\\n ', ' if', ' i', ' %', ' 3', ' ==', ' 0', ' and', ' i', ' %', ' 5', ' ==', ' 0', ':', '\\n   ', ' print', '(\"', 'FizzBuzz', '\")', '\\n ', ' elif', ' i', ' %', ' 3', ' ==', ' 0', ':', '\\n   ', ' print', '(\"', 'Fizz', '\")', '\\n ', ' elif', ' i', ' %', ' 5', ' ==', ' 0', ':', '\\n   ', ' print', '(\"', 'Buzz', '\")', '\\n ', ' else', ':', '\\n   ', ' print', '(', 'i', ')', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndmtFTtLVh-g",
        "outputId": "f72062bf-de99-4845-ea76-324678354118"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "# GPT-2 (does not merge spaces)\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "print(enc.encode(\"  hello world!!\"))\n",
        "\n",
        "# GPT-4 (merges spaces)\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "print(enc.encode(\"  hello world!!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESQH0-ciU527",
        "outputId": "f2e096b3-961e-4baa-b32a-ab56da645253"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[220, 23748, 995, 3228]\n",
            "[220, 24748, 1917, 3001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to download these two files:\n",
        "!wget https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/vocab.bpe\n",
        "!wget https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/encoder.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WFXnAlHVgjX",
        "outputId": "9ff1eab0-985e-4a5b-8758-acb9a89bdec8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-10 12:56:28--  https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/vocab.bpe\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 57.150.97.129\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|57.150.97.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 456318 (446K) [application/octet-stream]\n",
            "Saving to: ‚Äòvocab.bpe.1‚Äô\n",
            "\n",
            "vocab.bpe.1         100%[===================>] 445.62K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-08-10 12:56:28 (3.41 MB/s) - ‚Äòvocab.bpe.1‚Äô saved [456318/456318]\n",
            "\n",
            "--2024-08-10 12:56:28--  https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/encoder.json\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 57.150.97.129\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|57.150.97.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1042301 (1018K) [application/json]\n",
            "Saving to: ‚Äòencoder.json‚Äô\n",
            "\n",
            "encoder.json        100%[===================>]   1018K  4.07MB/s    in 0.2s    \n",
            "\n",
            "2024-08-10 12:56:28 (4.07 MB/s) - ‚Äòencoder.json‚Äô saved [1042301/1042301]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "\n",
        "with open('encoder.json', 'r') as f:\n",
        "  encoder = json.load(f)\n",
        "\n",
        "with open('vocab.bpe', 'r') as f:\n",
        "  bpe_data = f.read()\n",
        "bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]"
      ],
      "metadata": {
        "id": "358fffIsWopN"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###special tokens"
      ],
      "metadata": {
        "id": "jZexFGR9X6iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoder) # 256 raw byte tokens. 50,000 merges. +1 special token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WVBaZfdXRLj",
        "outputId": "1ba7dec6-8b6e-4f57-d6dc-16a81ff6390b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder['<|endoftext|>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVfWl8WfYBTt",
        "outputId": "da72270d-7091-4714-c33a-967cac2292cb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "print(enc.encode(\"ÏïàÎÖïÌïòÏÑ∏Ïöî üëè (hello in korean!)\"))\n",
        "print(enc.decode(enc.encode(\"ÏïàÎÖïÌïòÏÑ∏Ïöî üëè (hello in korean!)\")) == \"ÏïàÎÖïÌïòÏÑ∏Ïöî üëè (hello in korean!)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51ENRVRkYCbK",
        "outputId": "eb8003fb-9e88-4a66-f0f3-4db35e2e449a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31495, 230, 75265, 243, 92245, 62904, 237, 320, 15339, 304, 597, 46295, 16715]\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "# write a toy.txt file with some random text\n",
        "with open(\"toy.txt\", \"w\", encoding=\"utf-8\"):\n",
        "  f.write(\"SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "8NyhaXxhaP9w",
        "outputId": "a05d7736-dc33-45c7-ef17-99e83b7392e7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "I/O operation on closed file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-a71a34e75d38>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# write a toy.txt file with some random text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"toy.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "# write a toy.txt file with some random text\n",
        "with open(\"toy.txt\", \"w\", encoding=\"utf-8\") as f: # Use 'f' to write into the file\n",
        "  f.write(\"SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. \")\n",
        "\n",
        "# train a sentencepiece model on it\n",
        "# the settings here are (best effort) those used for training Llama 2\n",
        "import os\n",
        "import sentencepiece as spm\n",
        "\n",
        "options = dict(\n",
        "    # input spec\n",
        "    input=\"toy.txt\",\n",
        "    input_format=\"text\",\n",
        "    # output spec\n",
        "    model_prefix=\"tok400\", # output filename prefix\n",
        "    # algorithm spec\n",
        "    # BPE alg\n",
        "    model_type=\"bpe\",\n",
        "    vocab_size=400,\n",
        "    # normalization\n",
        "    normalization_rule_name=\"identity\", # ew, turn off normalization\n",
        "    remove_extra_whitespaces=False,\n",
        "    input_sentence_size=200000000, # max number of training sentences\n",
        "    max_sentence_length=4192, # max number of bytes per sentence\n",
        "    seed_sentencepiece_size=1000000,\n",
        "    shuffle_input_sentence=True,\n",
        "    # rare word treatment\n",
        "    character_coverage=0.99995,\n",
        "    byte_fallback=True,\n",
        "    # merge rules\n",
        "    split_digits=True,\n",
        "    split_by_unicode_script=True,\n",
        "    split_by_whitespace=True,\n",
        "    split_by_number=True,\n",
        "    max_sentencepiece_length=16,\n",
        "    add_dummy_prefix=True,\n",
        "    allow_whitespace_only_pieces=True,\n",
        "    # special tokens\n",
        "    unk_id=0, # the UNK token MUST exist\n",
        "    bos_id=1, # the others are optional, set to -1 to turn off\n",
        "    eos_id=2,\n",
        "    pad_id=-1,\n",
        "    # systems\n",
        "    num_threads=os.cpu_count(), # use ~all system resources\n",
        ")\n",
        "\n",
        "spm.SentencePieceTrainer.train(**options)"
      ],
      "metadata": {
        "id": "LCqET8oxbRv3"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"tok400.model\")\n",
        "vocab = [[sp.id_to_piece(idx), idx] for idx in range(sp.get_piece_size())]\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy3mRR5GdpgP",
        "outputId": "7b990448-13cf-487a-ed55-2c768c5d57e7"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<unk>', 0],\n",
              " ['<s>', 1],\n",
              " ['</s>', 2],\n",
              " ['<0x00>', 3],\n",
              " ['<0x01>', 4],\n",
              " ['<0x02>', 5],\n",
              " ['<0x03>', 6],\n",
              " ['<0x04>', 7],\n",
              " ['<0x05>', 8],\n",
              " ['<0x06>', 9],\n",
              " ['<0x07>', 10],\n",
              " ['<0x08>', 11],\n",
              " ['<0x09>', 12],\n",
              " ['<0x0A>', 13],\n",
              " ['<0x0B>', 14],\n",
              " ['<0x0C>', 15],\n",
              " ['<0x0D>', 16],\n",
              " ['<0x0E>', 17],\n",
              " ['<0x0F>', 18],\n",
              " ['<0x10>', 19],\n",
              " ['<0x11>', 20],\n",
              " ['<0x12>', 21],\n",
              " ['<0x13>', 22],\n",
              " ['<0x14>', 23],\n",
              " ['<0x15>', 24],\n",
              " ['<0x16>', 25],\n",
              " ['<0x17>', 26],\n",
              " ['<0x18>', 27],\n",
              " ['<0x19>', 28],\n",
              " ['<0x1A>', 29],\n",
              " ['<0x1B>', 30],\n",
              " ['<0x1C>', 31],\n",
              " ['<0x1D>', 32],\n",
              " ['<0x1E>', 33],\n",
              " ['<0x1F>', 34],\n",
              " ['<0x20>', 35],\n",
              " ['<0x21>', 36],\n",
              " ['<0x22>', 37],\n",
              " ['<0x23>', 38],\n",
              " ['<0x24>', 39],\n",
              " ['<0x25>', 40],\n",
              " ['<0x26>', 41],\n",
              " ['<0x27>', 42],\n",
              " ['<0x28>', 43],\n",
              " ['<0x29>', 44],\n",
              " ['<0x2A>', 45],\n",
              " ['<0x2B>', 46],\n",
              " ['<0x2C>', 47],\n",
              " ['<0x2D>', 48],\n",
              " ['<0x2E>', 49],\n",
              " ['<0x2F>', 50],\n",
              " ['<0x30>', 51],\n",
              " ['<0x31>', 52],\n",
              " ['<0x32>', 53],\n",
              " ['<0x33>', 54],\n",
              " ['<0x34>', 55],\n",
              " ['<0x35>', 56],\n",
              " ['<0x36>', 57],\n",
              " ['<0x37>', 58],\n",
              " ['<0x38>', 59],\n",
              " ['<0x39>', 60],\n",
              " ['<0x3A>', 61],\n",
              " ['<0x3B>', 62],\n",
              " ['<0x3C>', 63],\n",
              " ['<0x3D>', 64],\n",
              " ['<0x3E>', 65],\n",
              " ['<0x3F>', 66],\n",
              " ['<0x40>', 67],\n",
              " ['<0x41>', 68],\n",
              " ['<0x42>', 69],\n",
              " ['<0x43>', 70],\n",
              " ['<0x44>', 71],\n",
              " ['<0x45>', 72],\n",
              " ['<0x46>', 73],\n",
              " ['<0x47>', 74],\n",
              " ['<0x48>', 75],\n",
              " ['<0x49>', 76],\n",
              " ['<0x4A>', 77],\n",
              " ['<0x4B>', 78],\n",
              " ['<0x4C>', 79],\n",
              " ['<0x4D>', 80],\n",
              " ['<0x4E>', 81],\n",
              " ['<0x4F>', 82],\n",
              " ['<0x50>', 83],\n",
              " ['<0x51>', 84],\n",
              " ['<0x52>', 85],\n",
              " ['<0x53>', 86],\n",
              " ['<0x54>', 87],\n",
              " ['<0x55>', 88],\n",
              " ['<0x56>', 89],\n",
              " ['<0x57>', 90],\n",
              " ['<0x58>', 91],\n",
              " ['<0x59>', 92],\n",
              " ['<0x5A>', 93],\n",
              " ['<0x5B>', 94],\n",
              " ['<0x5C>', 95],\n",
              " ['<0x5D>', 96],\n",
              " ['<0x5E>', 97],\n",
              " ['<0x5F>', 98],\n",
              " ['<0x60>', 99],\n",
              " ['<0x61>', 100],\n",
              " ['<0x62>', 101],\n",
              " ['<0x63>', 102],\n",
              " ['<0x64>', 103],\n",
              " ['<0x65>', 104],\n",
              " ['<0x66>', 105],\n",
              " ['<0x67>', 106],\n",
              " ['<0x68>', 107],\n",
              " ['<0x69>', 108],\n",
              " ['<0x6A>', 109],\n",
              " ['<0x6B>', 110],\n",
              " ['<0x6C>', 111],\n",
              " ['<0x6D>', 112],\n",
              " ['<0x6E>', 113],\n",
              " ['<0x6F>', 114],\n",
              " ['<0x70>', 115],\n",
              " ['<0x71>', 116],\n",
              " ['<0x72>', 117],\n",
              " ['<0x73>', 118],\n",
              " ['<0x74>', 119],\n",
              " ['<0x75>', 120],\n",
              " ['<0x76>', 121],\n",
              " ['<0x77>', 122],\n",
              " ['<0x78>', 123],\n",
              " ['<0x79>', 124],\n",
              " ['<0x7A>', 125],\n",
              " ['<0x7B>', 126],\n",
              " ['<0x7C>', 127],\n",
              " ['<0x7D>', 128],\n",
              " ['<0x7E>', 129],\n",
              " ['<0x7F>', 130],\n",
              " ['<0x80>', 131],\n",
              " ['<0x81>', 132],\n",
              " ['<0x82>', 133],\n",
              " ['<0x83>', 134],\n",
              " ['<0x84>', 135],\n",
              " ['<0x85>', 136],\n",
              " ['<0x86>', 137],\n",
              " ['<0x87>', 138],\n",
              " ['<0x88>', 139],\n",
              " ['<0x89>', 140],\n",
              " ['<0x8A>', 141],\n",
              " ['<0x8B>', 142],\n",
              " ['<0x8C>', 143],\n",
              " ['<0x8D>', 144],\n",
              " ['<0x8E>', 145],\n",
              " ['<0x8F>', 146],\n",
              " ['<0x90>', 147],\n",
              " ['<0x91>', 148],\n",
              " ['<0x92>', 149],\n",
              " ['<0x93>', 150],\n",
              " ['<0x94>', 151],\n",
              " ['<0x95>', 152],\n",
              " ['<0x96>', 153],\n",
              " ['<0x97>', 154],\n",
              " ['<0x98>', 155],\n",
              " ['<0x99>', 156],\n",
              " ['<0x9A>', 157],\n",
              " ['<0x9B>', 158],\n",
              " ['<0x9C>', 159],\n",
              " ['<0x9D>', 160],\n",
              " ['<0x9E>', 161],\n",
              " ['<0x9F>', 162],\n",
              " ['<0xA0>', 163],\n",
              " ['<0xA1>', 164],\n",
              " ['<0xA2>', 165],\n",
              " ['<0xA3>', 166],\n",
              " ['<0xA4>', 167],\n",
              " ['<0xA5>', 168],\n",
              " ['<0xA6>', 169],\n",
              " ['<0xA7>', 170],\n",
              " ['<0xA8>', 171],\n",
              " ['<0xA9>', 172],\n",
              " ['<0xAA>', 173],\n",
              " ['<0xAB>', 174],\n",
              " ['<0xAC>', 175],\n",
              " ['<0xAD>', 176],\n",
              " ['<0xAE>', 177],\n",
              " ['<0xAF>', 178],\n",
              " ['<0xB0>', 179],\n",
              " ['<0xB1>', 180],\n",
              " ['<0xB2>', 181],\n",
              " ['<0xB3>', 182],\n",
              " ['<0xB4>', 183],\n",
              " ['<0xB5>', 184],\n",
              " ['<0xB6>', 185],\n",
              " ['<0xB7>', 186],\n",
              " ['<0xB8>', 187],\n",
              " ['<0xB9>', 188],\n",
              " ['<0xBA>', 189],\n",
              " ['<0xBB>', 190],\n",
              " ['<0xBC>', 191],\n",
              " ['<0xBD>', 192],\n",
              " ['<0xBE>', 193],\n",
              " ['<0xBF>', 194],\n",
              " ['<0xC0>', 195],\n",
              " ['<0xC1>', 196],\n",
              " ['<0xC2>', 197],\n",
              " ['<0xC3>', 198],\n",
              " ['<0xC4>', 199],\n",
              " ['<0xC5>', 200],\n",
              " ['<0xC6>', 201],\n",
              " ['<0xC7>', 202],\n",
              " ['<0xC8>', 203],\n",
              " ['<0xC9>', 204],\n",
              " ['<0xCA>', 205],\n",
              " ['<0xCB>', 206],\n",
              " ['<0xCC>', 207],\n",
              " ['<0xCD>', 208],\n",
              " ['<0xCE>', 209],\n",
              " ['<0xCF>', 210],\n",
              " ['<0xD0>', 211],\n",
              " ['<0xD1>', 212],\n",
              " ['<0xD2>', 213],\n",
              " ['<0xD3>', 214],\n",
              " ['<0xD4>', 215],\n",
              " ['<0xD5>', 216],\n",
              " ['<0xD6>', 217],\n",
              " ['<0xD7>', 218],\n",
              " ['<0xD8>', 219],\n",
              " ['<0xD9>', 220],\n",
              " ['<0xDA>', 221],\n",
              " ['<0xDB>', 222],\n",
              " ['<0xDC>', 223],\n",
              " ['<0xDD>', 224],\n",
              " ['<0xDE>', 225],\n",
              " ['<0xDF>', 226],\n",
              " ['<0xE0>', 227],\n",
              " ['<0xE1>', 228],\n",
              " ['<0xE2>', 229],\n",
              " ['<0xE3>', 230],\n",
              " ['<0xE4>', 231],\n",
              " ['<0xE5>', 232],\n",
              " ['<0xE6>', 233],\n",
              " ['<0xE7>', 234],\n",
              " ['<0xE8>', 235],\n",
              " ['<0xE9>', 236],\n",
              " ['<0xEA>', 237],\n",
              " ['<0xEB>', 238],\n",
              " ['<0xEC>', 239],\n",
              " ['<0xED>', 240],\n",
              " ['<0xEE>', 241],\n",
              " ['<0xEF>', 242],\n",
              " ['<0xF0>', 243],\n",
              " ['<0xF1>', 244],\n",
              " ['<0xF2>', 245],\n",
              " ['<0xF3>', 246],\n",
              " ['<0xF4>', 247],\n",
              " ['<0xF5>', 248],\n",
              " ['<0xF6>', 249],\n",
              " ['<0xF7>', 250],\n",
              " ['<0xF8>', 251],\n",
              " ['<0xF9>', 252],\n",
              " ['<0xFA>', 253],\n",
              " ['<0xFB>', 254],\n",
              " ['<0xFC>', 255],\n",
              " ['<0xFD>', 256],\n",
              " ['<0xFE>', 257],\n",
              " ['<0xFF>', 258],\n",
              " ['‚ñÅt', 259],\n",
              " ['er', 260],\n",
              " ['en', 261],\n",
              " ['ed', 262],\n",
              " ['in', 263],\n",
              " ['et', 264],\n",
              " ['is', 265],\n",
              " ['iz', 266],\n",
              " ['or', 267],\n",
              " ['ra', 268],\n",
              " ['an', 269],\n",
              " ['ce', 270],\n",
              " ['eu', 271],\n",
              " ['ex', 272],\n",
              " ['he', 273],\n",
              " ['ok', 274],\n",
              " ['pr', 275],\n",
              " ['‚ñÅN', 276],\n",
              " ['‚ñÅm', 277],\n",
              " ['‚ñÅs', 278],\n",
              " ['ext', 279],\n",
              " ['ral', 280],\n",
              " ['‚ñÅan', 281],\n",
              " ['‚ñÅis', 282],\n",
              " ['‚ñÅpr', 283],\n",
              " ['eniz', 284],\n",
              " ['‚ñÅthe', 285],\n",
              " ['eural', 286],\n",
              " ['‚ñÅtext', 287],\n",
              " ['enizer', 288],\n",
              " ['okenizer', 289],\n",
              " ['Pi', 290],\n",
              " ['ab', 291],\n",
              " ['ar', 292],\n",
              " ['as', 293],\n",
              " ['at', 294],\n",
              " ['de', 295],\n",
              " ['em', 296],\n",
              " ['io', 297],\n",
              " ['ly', 298],\n",
              " ['ns', 299],\n",
              " ['oc', 300],\n",
              " ['st', 301],\n",
              " ['ul', 302],\n",
              " ['up', 303],\n",
              " ['wh', 304],\n",
              " ['‚ñÅS', 305],\n",
              " ['‚ñÅd', 306],\n",
              " ['‚ñÅf', 307],\n",
              " ['‚ñÅg', 308],\n",
              " ['‚ñÅn', 309],\n",
              " ['‚ñÅu', 310],\n",
              " ['‚ñÅv', 311],\n",
              " ['Pie', 312],\n",
              " ['ain', 313],\n",
              " ['ary', 314],\n",
              " ['bas', 315],\n",
              " ['del', 316],\n",
              " ['ems', 317],\n",
              " ['ent', 318],\n",
              " ['ere', 319],\n",
              " ['erm', 320],\n",
              " ['erv', 321],\n",
              " ['etw', 322],\n",
              " ['ing', 323],\n",
              " ['ion', 324],\n",
              " ['ior', 325],\n",
              " ['ize', 326],\n",
              " ['ork', 327],\n",
              " ['yst', 328],\n",
              " ['‚ñÅmo', 329],\n",
              " ['‚ñÅto', 330],\n",
              " ['‚ñÅwh', 331],\n",
              " ['abul', 332],\n",
              " ['edet', 333],\n",
              " ['ence', 334],\n",
              " ['ener', 335],\n",
              " ['ined', 336],\n",
              " ['ised', 337],\n",
              " ['nsup', 338],\n",
              " ['rain', 339],\n",
              " ['‚ñÅand', 340],\n",
              " ['‚ñÅdet', 341],\n",
              " ['‚ñÅfor', 342],\n",
              " ['‚ñÅvoc', 343],\n",
              " ['Piece', 344],\n",
              " ['ainly', 345],\n",
              " ['ation', 346],\n",
              " ['based', 347],\n",
              " ['‚ñÅNetw', 348],\n",
              " ['‚ñÅSent', 349],\n",
              " ['‚ñÅsize', 350],\n",
              " ['‚ñÅsyst', 351],\n",
              " ['‚ñÅgener', 352],\n",
              " ['‚ñÅmodel', 353],\n",
              " ['‚ñÅprior', 354],\n",
              " ['‚ñÅtrain', 355],\n",
              " ['‚ñÅunsup', 356],\n",
              " ['‚ñÅwhere', 357],\n",
              " ['abulary', 358],\n",
              " ['edeterm', 359],\n",
              " ['ervised', 360],\n",
              " ['‚ñÅNeural', 361],\n",
              " ['‚ñÅmainly', 362],\n",
              " ['‚ñÅneural', 363],\n",
              " ['‚ñÅNetwork', 364],\n",
              " ['‚ñÅsystems', 365],\n",
              " ['encePiece', 366],\n",
              " ['‚ñÅtraining', 367],\n",
              " ['‚ñÅpredeterm', 368],\n",
              " ['‚ñÅtokenizer', 369],\n",
              " ['e', 370],\n",
              " ['‚ñÅ', 371],\n",
              " ['r', 372],\n",
              " ['t', 373],\n",
              " ['n', 374],\n",
              " ['i', 375],\n",
              " ['a', 376],\n",
              " ['o', 377],\n",
              " ['s', 378],\n",
              " ['d', 379],\n",
              " ['l', 380],\n",
              " ['u', 381],\n",
              " ['m', 382],\n",
              " ['c', 383],\n",
              " ['h', 384],\n",
              " ['k', 385],\n",
              " ['p', 386],\n",
              " ['y', 387],\n",
              " ['z', 388],\n",
              " ['N', 389],\n",
              " ['b', 390],\n",
              " ['g', 391],\n",
              " ['v', 392],\n",
              " ['w', 393],\n",
              " ['x', 394],\n",
              " ['-', 395],\n",
              " ['.', 396],\n",
              " ['P', 397],\n",
              " ['S', 398],\n",
              " ['f', 399]]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = sp.encode(\"ÏïàÎÖïÌïòÏÑ∏Ïöî üëè (hello in korean!)\")\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znXkuEtOesKO",
        "outputId": "b3981337-139d-49d4-d3d0-a7517f16c472"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[371,\n",
              " 239,\n",
              " 152,\n",
              " 139,\n",
              " 238,\n",
              " 136,\n",
              " 152,\n",
              " 240,\n",
              " 152,\n",
              " 155,\n",
              " 239,\n",
              " 135,\n",
              " 187,\n",
              " 239,\n",
              " 157,\n",
              " 151,\n",
              " 371,\n",
              " 243,\n",
              " 162,\n",
              " 148,\n",
              " 146,\n",
              " 371,\n",
              " 43,\n",
              " 273,\n",
              " 380,\n",
              " 380,\n",
              " 377,\n",
              " 371,\n",
              " 263,\n",
              " 371,\n",
              " 385,\n",
              " 267,\n",
              " 370,\n",
              " 269,\n",
              " 36,\n",
              " 44]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([sp.id_to_piece(idx) for idx in ids])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP56SnnFexyR",
        "outputId": "73a2f632-7512-4d7a-943f-73134a960f68"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['‚ñÅ', '<0xEC>', '<0x95>', '<0x88>', '<0xEB>', '<0x85>', '<0x95>', '<0xED>', '<0x95>', '<0x98>', '<0xEC>', '<0x84>', '<0xB8>', '<0xEC>', '<0x9A>', '<0x94>', '‚ñÅ', '<0xF0>', '<0x9F>', '<0x91>', '<0x8F>', '‚ñÅ', '<0x28>', 'he', 'l', 'l', 'o', '‚ñÅ', 'in', '‚ñÅ', 'k', 'or', 'e', 'an', '<0x21>', '<0x29>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8s3D-Aaie4CD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}